{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "(7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** You are presented with the task of doing predictions on a long time-series. You think a **temporal convolution network** (TCN) could be a good idea. For the model you decide on using filter size of 3, 2 hidden layers and dilations of $1, 3,$ and $5$ for the first hidden layer, the second hidden layer and the output layer respectively. What is the perceptive field of this model?\n",
    "\n",
    "<div style=\"text-align: right\">(2p)</div>\n",
    "\n",
    "**Answer:** 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** After runing the model you realise that you have long-time dependences in the data that you are unable to capture with a TCN, so you decide to work with a **recurrent neural network** (RNN) instead. You are now tasked with the problem of fitting this model using your singular time-series. Describe 2 different approaches to train an RNN when dealing with a single time-series, discuss the pros and cons of these approaches.\n",
    "<div style=\"text-align: right\">(5p)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Do nothing\n",
    "# 2. Random windows \n",
    "#A total of N sequences of equal length (n) are randomly sampled from the sequence and used as different sample to train the model. Each time a new different sequence is trained, the hidden states are reset to 0.\n",
    "#pros: parallizing calculation, Speeding up gradient computations.\n",
    "#cons: we can not capture correlation between sequences.\n",
    "# 3. Stateful training\n",
    "#Split the sequence into N subsequences in order, Process the sub-sequences in order. Each time a different sequence is trained, the hidden states will inherit the value of the final hidden states of the previous sequence.\n",
    "#pros: we can capture correalation between sequences\n",
    "#cons: this process has to be serial so it's slow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
